{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4aMbQiz6doDx"
      },
      "outputs": [],
      "source": [
        "#IMPORTING LIBRARIES\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#IMPORTING DATASET\n",
        "dataset = zipfile.ZipFile(\"/content/Untitled Folder/kagglecatsanddogs_5340.zip\")\n",
        "dataset.extractall()\n",
        "img = []\n",
        "label = []\n",
        "for i in os.listdir(\"PetImages\"):\n",
        "  for j in os.listdir(\"PetImages/\"+i):\n",
        "    if i ==  \"Cat\":\n",
        "      label.append(0)\n",
        "    else:\n",
        "      label.append(1)\n",
        "    img.append(os.path.join(\"PetImages\",i,j)) \n"
      ],
      "metadata": {
        "id": "XslzC_IwjwuK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CREATING DATAFRAME\n",
        "img_df = pd.DataFrame(img)\n",
        "img_label = pd.DataFrame(label)\n",
        "df = pd.concat([img_df,img_label],axis=1)\n",
        "df.columns = [\"Image\",\"Label\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "bcb1ur446cl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DELETING THE FILES WHICH IS NOT AN IMAGE\n",
        "for i in df[\"Image\"]:\n",
        "  if  i[-3:] != \"jpg\":\n",
        "    df.drop(axis=0)"
      ],
      "metadata": {
        "id": "8xBsCqv5xWCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VISUALIZING WEIGHT\n",
        "import seaborn as sns\n",
        "sns.countplot(df[\"label\"])"
      ],
      "metadata": {
        "id": "zADyykDJ2CQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DROPPING THE WRONG DATA \n",
        "df = df[df[\"Image\"] != 'PetImages\\\\Cat\\\\666.jpg']\n",
        "df = df[df[\"Image\"] != 'PetImages\\\\Cat\\\\Thumbs.db']\n",
        "df = df[df[\"Image\"] != 'PetImages\\\\Dog\\\\11702.jpg']\n",
        "df = df[df[\"Image\"] != 'PetImages\\\\Dog\\\\Thumbs.db']\n",
        "df = df[df[\"Image\"] != 'PetImages\\\\Cat\\\\10493.jpg']"
      ],
      "metadata": {
        "id": "pGCpgdMSG0xL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "tf.image.resize(\n",
        "    df[\"Image\"],\n",
        "    [500,500],\n",
        "    method=ResizeMethod.BILINEAR,\n",
        "    preserve_aspect_ratio=False,\n",
        "    antialias=False,\n",
        "    name=None\n",
        ")"
      ],
      "metadata": {
        "id": "E9VhdaXlyvpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DATA VISUALIZATION\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "dogs = []\n",
        "\n",
        "dogs = df[\"Image\"].loc[df[\"Label\"] == 1]\n",
        "for i in range(25):\n",
        "    asd = random.randint(12501,25000)\n",
        "    dogs.append(df[\"Image\"].iloc[asd])\n",
        "for index,i in enumerate(list):\n",
        "    plt.subplot(5,5,index+1) \n",
        "    image = load_img(i)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Dogs\")\n",
        "    plt.axis(\"off\")\n",
        "    \n",
        "import random\n",
        "cats = []\n",
        "cats = df[\"Image\"].loc[df[\"Label\"] == 0]\n",
        "for i in range(25):\n",
        "    asd = random.randint(0,12499)\n",
        "    cats.append(df[\"Image\"].iloc[asd])\n",
        "\n",
        "for index,i in enumerate(list_2):\n",
        "    plt.subplot(5,5,index+1) \n",
        "    image = load_img(i)\n",
        "    plt.imshow(image)\n",
        "    plt.title(\"Cats\")\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "vtLkrGec0a6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MODELIZATION\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df['Label'] = df['Label'].astype('str')\n",
        "train,test = train_test_split(df,test_size=0.33,random_state=5)\n"
      ],
      "metadata": {
        "id": "Dutdl5XG14jF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_generator = ImageDataGenerator(\n",
        "    rescale = 1./255,  \n",
        "    rotation_range = 40, \n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True,\n",
        "    fill_mode = 'nearest'\n",
        ")\n",
        "\n",
        "val_generator = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "train_iterator = train_generator.flow_from_dataframe(\n",
        "    train, \n",
        "    x_col='Image', \n",
        "    y_col='Label', \n",
        "    target_size=(128,128), \n",
        "    batch_size=512, \n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "val_iterator = val_generator.flow_from_dataframe(\n",
        "    test, \n",
        "    x_col='Image', \n",
        "    y_col='Label', \n",
        "    target_size=(128,128), \n",
        "    batch_size=512, \n",
        "    class_mode='binary'\n",
        ")\n",
        "test_images = val_generator.flow_from_dataframe(\n",
        "    dataframe=df,\n",
        "    x_col='Image',\n",
        "    y_col='Label',\n",
        "    target_size=(128, 128),\n",
        "    color_mode='rgb',\n",
        "    class_mode='binary',\n",
        "    batch_size=32,\n",
        "    shuffle=False)"
      ],
      "metadata": {
        "id": "EAu0oHPm0011"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "model = Sequential([\n",
        "                    Conv2D(16, (3,3), activation='relu', input_shape=(128,128,3)),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Conv2D(32, (3,3), activation='relu'),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Conv2D(64, (3,3), activation='relu'),\n",
        "                    MaxPool2D((2,2)),\n",
        "                    Flatten(),\n",
        "                    Dense(512, activation='relu'),\n",
        "                    Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "ERcqXMep3JXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAIN AND SCORE SCORE\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "history = model.fit(train_iterator, epochs=10, validation_data=val_iterator)\n",
        "\n",
        "results = model.evaluate(test_images, verbose=0)\n",
        "\n",
        "print(\"Loss -> {:.2f}\".format(results[0]))\n",
        "print(\"Accuracy Point -> {:.2f}%\".format(results[1] * 100))"
      ],
      "metadata": {
        "id": "v_w2wb2w3SOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#HEATMAP\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "pred = (model.predict(test_images) >= 0.5).astype(np.int)\n",
        "\n",
        "cm = confusion_matrix(test_images.labels, pred, labels=[0, 1])\n",
        "clr = classification_report(test_images.labels, pred, labels=[0, 1])\n",
        "                        \n",
        "LABELS=[\"Cat\", \"Dog\"]\n",
        "\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n",
        "plt.xticks(ticks=[0.5, 1.5], labels=[\"Cat\", \"Dog\"])\n",
        "plt.yticks(ticks=[0.5, 1.5], labels=[\"Cat\", \"Dog\"])\n",
        "plt.xlabel(\"Prediction\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AAdXLNB_DCGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = history.history['accuracy']\n",
        "val_score = history.history['val_accuracy']\n",
        "epochs = range(len(score))\n",
        "\n",
        "plt.plot(epochs, score, 'b', label='Training Accuracy')\n",
        "plt.plot(epochs, val_score, 'r', label='Validation Accuracy')\n",
        "plt.title('Accuracy Graph')\n",
        "plt.legend()\n",
        "plt.figure()\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "plt.title('Loss Graph')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GuYRQWCh3gOr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}